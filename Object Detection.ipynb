{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72f5c59-4aba-4a1f-adcf-59673c26a932",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e2c6a917-2cb2-4893-9215-1ce2cc673c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ultralytics\n",
    "#pip install python-dotenv\n",
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512a7696-108d-4bbe-b9db-ffb6211e78fe",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3b583db8-a74c-4f0d-a658-441e2a76906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard\n",
    "import os\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Data & image handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from torchvision.models.detection import (\n",
    "    fasterrcnn_resnet50_fpn,\n",
    "    FasterRCNN_ResNet50_FPN_Weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbdcf9-5456-43df-a227-62e1507fd236",
   "metadata": {},
   "source": [
    "## Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "644ceb14-d418-4c22-885f-6d9c89bc60d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project folder contains 10 files/directories\n",
      "Image folder contains   11 files\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ENV_FILE = \"projectrootfolderpath.env\" # environment file with folder paths\n",
    "PROJECT_FOLDER_VAR = \"PROJECT_FOLDER\" # project folder path\n",
    "IMAGE_FOLDER_VAR = \"IMAGE_FOLDER\" # image folder path\n",
    "OUTPUT_CSV_FILE = \"object_detection_comparison_results.csv\"\n",
    "# FILE_EXTS = () # If not specified, defaults (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv(PROJECT_ENV_FILE)\n",
    "\n",
    "# get folder paths\n",
    "project_folder = os.getenv(PROJECT_FOLDER_VAR)\n",
    "# error handling\n",
    "if project_folder is None:\n",
    "    raise ValueError(f\"ERROR: Environment variable '{PROJECT_FOLDER_VAR}' not set in {PROJECT_ENV_FILE}\")\n",
    "if not os.path.isdir(project_folder):\n",
    "    raise ValueError(f\"ERROR: '{project_folder}' is not a valid directory.\")\n",
    "\n",
    "#print(f\"Project folder: {project_folder}\")\n",
    "print(f\"Project folder contains {len(os.listdir(project_folder))} files/directories\")\n",
    "\n",
    "# get image folder paths\n",
    "image_folder = os.getenv(IMAGE_FOLDER_VAR)\n",
    "# error handling\n",
    "if image_folder is None:\n",
    "    raise ValueError(\"Environment variable IMAGE_FOLDER is not set.\")\n",
    "if not os.path.isdir(image_folder):\n",
    "    raise ValueError(f\"Path '{image_folder}' is not a valid directory.\")\n",
    "\n",
    "#print(f\"Image folder:   {image_folder}\")\n",
    "print(f\"Image folder contains   {len(os.listdir(image_folder))} files\")\n",
    "\n",
    "# output csv path project folder\n",
    "output_csv = os.path.join(project_folder, OUTPUT_CSV_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de4d82-f107-40a7-81af-af70a6e26c20",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f8a8d-a4ac-452f-b509-3602dc909051",
   "metadata": {},
   "source": [
    "### Image configuration helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "afe43871-817f-4417-bdf0-ae6abb934719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths(folder_path, valid_exts=None):\n",
    "    if folder_path is None:\n",
    "        raise ValueError(f\"ERROR: Image folder path is None.\")\n",
    "    if not os.path.isdir(folder_path):\n",
    "        raise ValueError(f\"ERROR: '{folder_path}' is not a valid directory.\")\n",
    "        \n",
    "    # set default extension types\n",
    "    if valid_exts is None: \n",
    "        valid_exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\") \n",
    "\n",
    "    # image files\n",
    "    image_files = sorted(\n",
    "        f for f in os.listdir(folder_path)\n",
    "        if f.lower().endswith(valid_exts)\n",
    "    )\n",
    "    \n",
    "    image_paths = [os.path.join(folder_path, f) for f in image_files]\n",
    "\n",
    "    # summary info\n",
    "    detected_exts = {os.path.splitext(f)[1].lower() for f in image_files}\n",
    "    summary = {\n",
    "        \"count\": len(image_files),\n",
    "        \"extensions\": detected_exts,\n",
    "        \"filenames\": image_files,\n",
    "    }\n",
    "\n",
    "    return image_files, image_paths, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1715a2-f521-45ef-957d-98bd874a6ed3",
   "metadata": {},
   "source": [
    "### Non-deep-learning image feature helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6f392340-b503-44ad-8ee3-36ed5c04e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(gray_array: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute Shannon entropy of a grayscale image.\n",
    "    gray_array should be a 2D uint8 array (0–255).\n",
    "    \"\"\"\n",
    "    # Histogram with 256 bins for 0–255\n",
    "    hist, _ = np.histogram(gray_array.ravel(), bins=256, range=(0, 255))\n",
    "    # Convert to probabilities\n",
    "    p = hist.astype(\"float32\")\n",
    "    total = p.sum()\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    p /= total\n",
    "    # Keep only non-zero probs to avoid log(0)\n",
    "    p = p[p > 0]\n",
    "    entropy = -np.sum(p * np.log2(p))\n",
    "    return float(entropy)\n",
    "\n",
    "def compute_edge_pixel_count(gray_array: np.ndarray,\n",
    "                             low_threshold: int = 100,\n",
    "                             high_threshold: int = 200) -> int:\n",
    "    \"\"\"\n",
    "    Count edge pixels using Canny edge detection.\n",
    "    gray_array should be a 2D uint8 array (0–255).\n",
    "    \"\"\"\n",
    "    edges = cv2.Canny(gray_array, low_threshold, high_threshold)\n",
    "    edge_count = int(np.count_nonzero(edges))\n",
    "    return edge_count\n",
    "\n",
    "def compute_colorfulness(rgb_array: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the Hasler–Süsstrunk colorfulness metric.\n",
    "    rgb_array should be in shape (H, W, 3) with values in [0, 255].\n",
    "    \"\"\"\n",
    "    # Separate channels\n",
    "    R = rgb_array[:, :, 2].astype(\"float32\")\n",
    "    G = rgb_array[:, :, 1].astype(\"float32\")\n",
    "    B = rgb_array[:, :, 0].astype(\"float32\")\n",
    "\n",
    "    # R-G and Y-B components\n",
    "    Rg = R - G\n",
    "    Yb = 0.5 * (R + G) - B\n",
    "\n",
    "    # Mean and standard deviation\n",
    "    mean_rg = np.mean(Rg)\n",
    "    mean_yb = np.mean(Yb)\n",
    "    std_rg = np.std(Rg)\n",
    "    std_yb = np.std(Yb)\n",
    "\n",
    "    # Colorfulness formula\n",
    "    std_root = np.sqrt(std_rg**2 + std_yb**2)\n",
    "    mean_root = np.sqrt(mean_rg**2 + mean_yb**2)\n",
    "    colorfulness = std_root + 0.3 * mean_root\n",
    "    return float(colorfulness)\n",
    "\n",
    "def extract_basic_image_features(image_path):\n",
    "    \"\"\"\n",
    "    Compute simple image statistics that do NOT use deep learning:\n",
    "    - width, height (pixels)\n",
    "    - aspect ratio (width / height)\n",
    "    - mean_brightness (0–1)\n",
    "    - entropy (Shannon entropy of grayscale)\n",
    "    - edge_pixel_count (Canny edge detector)\n",
    "    - colorfulness (Hasler–Süsstrunk metric)\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    width, height = img.size\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    rgb_array = np.asarray(img)               # shape (H, W, 3) in [0..255]\n",
    "    norm_array = rgb_array.astype(\"float32\") / 255.0\n",
    "\n",
    "    # Brightness: mean over all pixels/channels (0–1)\n",
    "    mean_brightness = float(norm_array.mean())\n",
    "\n",
    "    # Aspect ratio\n",
    "    aspect_ratio = width / height\n",
    "\n",
    "    # Grayscale array for entropy and edges\n",
    "    gray_array = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    entropy = compute_entropy(gray_array)\n",
    "    edge_pixel_count = compute_edge_pixel_count(gray_array)\n",
    "    colorfulness = compute_colorfulness(rgb_array)\n",
    "\n",
    "    return (width, height, aspect_ratio, mean_brightness, entropy, edge_pixel_count, colorfulness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb7a750-08c3-48d3-a743-017c211dc5e7",
   "metadata": {},
   "source": [
    "### Deep-learning model helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1d5d60ac-9769-45e8-967c-ae1a496d704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image to tensor\n",
    "to_tensor = T.ToTensor()\n",
    "\n",
    "def run_yolov8_on_image(image_path, model, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Run YOLOv8 on a single image.\n",
    "\n",
    "    Returns:\n",
    "    - elapsed_time (seconds)\n",
    "    - num_detections (count of boxes)\n",
    "    - avg_confidence (mean of box confidences, 0 if no detections)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Let the model use its own internal device setting.\n",
    "    results = model(\n",
    "        source=image_path,\n",
    "        conf=conf_threshold,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "\n",
    "    result = results[0]\n",
    "    boxes = result.boxes\n",
    "\n",
    "    num_detections = len(boxes)\n",
    "    if num_detections > 0:\n",
    "        confidences = boxes.conf.detach().cpu().numpy()\n",
    "        avg_conf = float(confidences.mean())\n",
    "    else:\n",
    "        avg_conf = 0.0\n",
    "\n",
    "    return elapsed, num_detections, avg_conf\n",
    "\n",
    "def run_fasterrcnn_on_image(image_path, model, device, score_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Run Faster R-CNN on a single image.\n",
    "\n",
    "    Returns:\n",
    "    - elapsed_time (seconds)\n",
    "    - num_detections (count of boxes with score >= threshold)\n",
    "    - avg_score (mean score of kept detections, 0 if none)\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = to_tensor(img).to(device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        outputs = model([img_tensor])\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "\n",
    "    output = outputs[0]\n",
    "    scores = output[\"scores\"].detach().cpu().numpy()\n",
    "\n",
    "    keep_mask = scores >= score_threshold\n",
    "    num_detections = int(keep_mask.sum())\n",
    "\n",
    "    if num_detections > 0:\n",
    "        avg_score = float(scores[keep_mask].mean())\n",
    "    else:\n",
    "        avg_score = 0.0\n",
    "\n",
    "    return elapsed, num_detections, avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b085a457-a0d4-4094-82f0-914de9699567",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860edc7e-e87f-4529-82ee-6ac00969dbc1",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1380d695-306f-48e3-83e3-1b058d3aae83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images\n",
      "Extensions detected: {'.jpg'}\n"
     ]
    }
   ],
   "source": [
    "image_files, image_paths, summary = load_image_paths(image_folder)\n",
    "\n",
    "if summary[\"count\"] == 0:\n",
    "    raise RuntimeError(\"No images found in the image folder.\")\n",
    "\n",
    "#print(\"\\nImage files found:\")\n",
    "#for f in image_files:\n",
    "#    print(\" -\", f)\n",
    "#print(f\"Total files: {len(image_files)}\\n\")\n",
    "\n",
    "print(f\"Found {summary['count']} images\")\n",
    "print(\"Extensions detected:\", summary[\"extensions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9078f1d7-d0ba-4928-8741-93e42e6abc6d",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8aa5391e-2f3c-47e8-890a-49bc1767e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loaded YOLO model: yolov8n.pt\n",
      "Loaded Faster R-CNN model with COCO weights\n"
     ]
    }
   ],
   "source": [
    "# Choose GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the metadata for the pre-trained model\n",
    "yolo_weights_path = \"yolov8m.pt\" if device.type == \"cuda\" else \"yolov8n.pt\"\n",
    "    \n",
    "# Load the pre-trained YOLO model (pick model size based on runtime capabilities\n",
    "yolo_model = YOLO(yolo_weights_path)\n",
    "yolo_model.to(device)\n",
    "\n",
    "print(\"Loaded YOLO model:\", yolo_weights_path)\n",
    "\n",
    "# Load the metadata for the pre-trained model\n",
    "frcnn_weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "\n",
    "# Load the pre-trained Faster R-CNN model\n",
    "fasterrcnn_model = fasterrcnn_resnet50_fpn(weights=frcnn_weights)\n",
    "fasterrcnn_model.to(device)\n",
    "fasterrcnn_model.eval()\n",
    "\n",
    "print(\"Loaded Faster R-CNN model with COCO weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa121c-bdc2-4a27-8ce6-0de6ca6c6394",
   "metadata": {},
   "source": [
    "## Run Models & Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7b792270-051d-47ff-8eb7-a9d9151e4ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image001.jpg ...\n",
      "[YOLOv8]    time=0.399s | detections=3 | avg_conf=0.376\n",
      "[FasterRCNN] time=13.639s | detections=4 | avg_score=0.893\n",
      "\n",
      "Processing image002.jpg ...\n",
      "[YOLOv8]    time=0.297s | detections=2 | avg_conf=0.912\n",
      "[FasterRCNN] time=15.400s | detections=7 | avg_score=0.812\n",
      "\n",
      "Processing image003.jpg ...\n",
      "[YOLOv8]    time=0.303s | detections=1 | avg_conf=0.372\n",
      "[FasterRCNN] time=11.287s | detections=1 | avg_score=0.713\n",
      "\n",
      "Processing image004.jpg ...\n",
      "[YOLOv8]    time=0.214s | detections=4 | avg_conf=0.595\n",
      "[FasterRCNN] time=12.175s | detections=9 | avg_score=0.797\n",
      "\n",
      "Processing image005.jpg ...\n",
      "[YOLOv8]    time=0.279s | detections=1 | avg_conf=0.920\n",
      "[FasterRCNN] time=9.484s | detections=0 | avg_score=0.000\n",
      "\n",
      "Processing image006.jpg ...\n",
      "[YOLOv8]    time=0.232s | detections=1 | avg_conf=0.262\n",
      "[FasterRCNN] time=10.363s | detections=3 | avg_score=0.690\n",
      "\n",
      "Processing image007.jpg ...\n",
      "[YOLOv8]    time=0.244s | detections=3 | avg_conf=0.290\n",
      "[FasterRCNN] time=10.223s | detections=32 | avg_score=0.646\n",
      "\n",
      "Processing image008.jpg ...\n",
      "[YOLOv8]    time=0.553s | detections=4 | avg_conf=0.750\n",
      "[FasterRCNN] time=10.390s | detections=5 | avg_score=0.837\n",
      "\n",
      "Processing image009.jpg ...\n",
      "[YOLOv8]    time=0.196s | detections=1 | avg_conf=0.394\n",
      "[FasterRCNN] time=10.548s | detections=0 | avg_score=0.000\n",
      "\n",
      "Processing image010.jpg ...\n",
      "[YOLOv8]    time=0.260s | detections=2 | avg_conf=0.580\n",
      "[FasterRCNN] time=9.314s | detections=10 | avg_score=0.898\n",
      "\n",
      "Processed 10 images.\n",
      "Results saved to: C:\\Users\\melin\\OneDrive\\MSBA\\503-Py II\\Take Home Assignment\\object_detection_comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "results_rows = []\n",
    "\n",
    "# run models on each image\n",
    "for img_name, img_path in zip(image_files, image_paths):\n",
    "    print(f\"\\nProcessing {img_name} ...\")\n",
    "\n",
    "    # Non–deep-learning features\n",
    "    (\n",
    "        width,\n",
    "        height,\n",
    "        aspect_ratio,\n",
    "        mean_brightness,\n",
    "        entropy,\n",
    "        edge_pixel_count,\n",
    "        colorfulness,\n",
    "    ) = extract_basic_image_features(img_path)\n",
    "\n",
    "    # YOLOv8 detection\n",
    "    yolo_time, yolo_count, yolo_avg_conf = run_yolov8_on_image(\n",
    "        img_path,\n",
    "        yolo_model,\n",
    "        conf_threshold=0.25,\n",
    "    )\n",
    "    \n",
    "    print(\n",
    "        f\"[YOLOv8]    time={yolo_time:.3f}s | \"\n",
    "        f\"detections={yolo_count} | \"\n",
    "        f\"avg_conf={yolo_avg_conf:.3f}\"\n",
    "    )\n",
    "\n",
    "    # Faster R-CNN detection\n",
    "    frcnn_time, frcnn_count, frcnn_avg_score = run_fasterrcnn_on_image(\n",
    "        img_path,\n",
    "        fasterrcnn_model,\n",
    "        device=device,\n",
    "        score_threshold=0.5,\n",
    "    )\n",
    "    print(\n",
    "        f\"[FasterRCNN] time={frcnn_time:.3f}s | \"\n",
    "        f\"detections={frcnn_count} | \"\n",
    "        f\"avg_score={frcnn_avg_score:.3f}\"\n",
    "    )\n",
    "\n",
    "    # Collect everything in a row for later tabular analysis\n",
    "    results_rows.append(\n",
    "        {\n",
    "            \"image\": img_name,\n",
    "            # Non–deep-learning features\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"aspect_ratio\": aspect_ratio,\n",
    "            \"mean_brightness\": mean_brightness,\n",
    "            \"entropy\": entropy,\n",
    "            \"edge_pixel_count\": edge_pixel_count,\n",
    "            \"colorfulness\": colorfulness,\n",
    "            # YOLO metrics\n",
    "            \"yolo_time_sec\": yolo_time,\n",
    "            \"yolo_objects\": yolo_count,\n",
    "            \"yolo_avg_conf\": yolo_avg_conf,\n",
    "            # Faster R-CNN metrics\n",
    "            \"frcnn_time_sec\": frcnn_time,\n",
    "            \"frcnn_objects\": frcnn_count,\n",
    "            \"frcnn_avg_score\": frcnn_avg_score,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"\\nProcessed {len(results_df)} images.\")\n",
    "print(f\"Results saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d95e57-a3e7-4a50-81a6-b2d14a987a69",
   "metadata": {},
   "source": [
    "## Save Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dc544c73-0345-405e-a108-3d4417dbeda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of results:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   image             10 non-null     object \n",
      " 1   width             10 non-null     int64  \n",
      " 2   height            10 non-null     int64  \n",
      " 3   aspect_ratio      10 non-null     float64\n",
      " 4   mean_brightness   10 non-null     float64\n",
      " 5   entropy           10 non-null     float64\n",
      " 6   edge_pixel_count  10 non-null     int64  \n",
      " 7   colorfulness      10 non-null     float64\n",
      " 8   yolo_time_sec     10 non-null     float64\n",
      " 9   yolo_objects      10 non-null     int64  \n",
      " 10  yolo_avg_conf     10 non-null     float64\n",
      " 11  frcnn_time_sec    10 non-null     float64\n",
      " 12  frcnn_objects     10 non-null     int64  \n",
      " 13  frcnn_avg_score   10 non-null     float64\n",
      "dtypes: float64(8), int64(5), object(1)\n",
      "memory usage: 1.2+ KB\n",
      "None\n",
      "\n",
      "Results Saved as object_detection_comparison_results.csv in project_folder\n",
      "Script finished\n"
     ]
    }
   ],
   "source": [
    "# Build dataframe\n",
    "results_df = pd.DataFrame(results_rows)\n",
    "print(\"\\nPreview of results:\")\n",
    "print(results_df.info())\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"\\nResults Saved as {OUTPUT_CSV_FILE} in project_folder\")\n",
    "print(\"Script finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
